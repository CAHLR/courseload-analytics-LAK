{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fab3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc46d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5044d",
   "metadata": {},
   "source": [
    "# Store workload predictions sem -> cid -> pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "fs = [\n",
    "    '../research-data/processed/course-features-2017 Spring.csv',\n",
    "    '../research-data/processed/course-features-2017 Fall.csv',\n",
    "    '../research-data/processed/course-features-2018 Spring.csv',\n",
    "    '../research-data/processed/course-features-2018 Fall.csv',\n",
    "    '../research-data/processed/course-features-2019 Spring.csv',\n",
    "    '../research-data/processed/course-features-2019 Fall.csv',\n",
    "    '../research-data/processed/course-features-2020 Spring.csv',\n",
    "    '../research-data/processed/course-features-2020 Fall.csv',\n",
    "    '../research-data/processed/course-features-2021 Spring.csv'\n",
    "]\n",
    "\n",
    "# Sems\n",
    "refs = [f.split('-')[-1].split('.')[0] for f in fs]\n",
    "\n",
    "# Output\n",
    "fs = [f'../research-data/processed/predicted-course-loads-{ref}.csv' for ref in refs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] \n",
    "for f, sem in zip(fs, refs):\n",
    "    tmp = pd.read_csv(f)\n",
    "    tmp = tmp[['course_name_number', 'cl_combined', 'secondary_sections']]\n",
    "    #tmp = tmp.set_index('course_name_number')\n",
    "    tmp = tmp.drop_duplicates()\n",
    "    tmp['#SEMESTER_YEAR_NAME_CONCAT'] = sem\n",
    "    tmp = tmp.rename(columns = {'course_name_number': 'COURSE_SUBJECT_NAME_NUMBER'})\n",
    "    tmp = tmp[['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER', 'secondary_sections', 'cl_combined']]\n",
    "    dfs.append(tmp)\n",
    "df_load = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ec86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091453e8",
   "metadata": {},
   "source": [
    "# Read in grade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2read = ['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER', 'COURSE_SUBJECT_SHORT_NM', \n",
    "             'STUDENT_CREDIT_HRS_NBR', 'GRADE_NM',\n",
    "             'GRADE_POINTS_NBR', 'GRADE_SORT_NBR', 'GRADE_SUBTYPE_DESC', 'SECTION_NBR',\n",
    "             'GRADE_TYPE_DESC', 'ANON_ID', 'SNAPSHOT_CODE', 'COURSE_CONTROL_NBR',\n",
    "             'CRS_ACADEMIC_DEPT_SHORT_NM', 'OFFERING_TYPE_DESC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade = pd.read_csv('../edw_askoski_student_grades_hashed.txt', \n",
    "                      sep='|', low_memory=False, usecols = cols2read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e81c3",
   "metadata": {},
   "source": [
    "# Sample data for cohort that enrolled in fall 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = pd.read_csv('../edw_askoski_student_cohorts_hashed.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall 2017 intake\n",
    "df_cohort_2017 = df_cohort[df_cohort['#SEMESTER_YEAR_NAME_CONCAT'] == '2017 Fall'].copy()\n",
    "\n",
    "df_cohort_2017 =\\\n",
    "    df_cohort_2017[['ANON_ID', '#SEMESTER_YEAR_NAME_CONCAT', 'YEARS_TO_GRADUATION', 'APPLICATION_ENTRY_TYPE']]\n",
    "\n",
    "df_cohort_2017.APPLICATION_ENTRY_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e10d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all relevant students are in the data set\n",
    "assert len(set(df_cohort_2017['ANON_ID']) - set(df_grade['ANON_ID'])) == 0, 'MISSING MATCHES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter\n",
    "df_grade_orig = df_grade.copy()\n",
    "df_grade = df_grade[df_grade['ANON_ID'].isin(set(df_cohort_2017['ANON_ID']))].copy() \n",
    "df_grade = df_grade[df_grade['#SEMESTER_YEAR_NAME_CONCAT'].isin(set(df_load['#SEMESTER_YEAR_NAME_CONCAT']))].copy()\n",
    "df_grade = df_grade[df_grade['#SEMESTER_YEAR_NAME_CONCAT'] != '2017 Spring'].copy()\n",
    "df_grade = df_grade[df_grade['COURSE_SUBJECT_NAME_NUMBER'] != '- -'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ec804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade['#SEMESTER_YEAR_NAME_CONCAT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e526fe",
   "metadata": {},
   "source": [
    "# Sample only primary sections with secondary sections based on which LMS data is used for workload prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter based on course ID\n",
    "perc_omitted = 1 - sum(df_grade['COURSE_SUBJECT_NAME_NUMBER'].isin(set(df_load['COURSE_SUBJECT_NAME_NUMBER'])))/df_grade.shape[0]\n",
    "df_grade_analysis = df_grade[df_grade['COURSE_SUBJECT_NAME_NUMBER'].isin(set(df_load['COURSE_SUBJECT_NAME_NUMBER']))].copy()\n",
    "print(f'Step 1: {round(perc_omitted*100, 2)}% omitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: If Semester x Course is available (no mean imputing), filter semester-level secondary sections\n",
    "#         Else, filter all available LMS secondary sections across semesters\n",
    "\n",
    "# Dict with course id ->  all secondary sections\n",
    "def eval_list_with_nan(s):\n",
    "    s = s.replace('nan, ', '')\n",
    "    try:\n",
    "        res = ast.literal_eval(s)\n",
    "    except:\n",
    "        res = []\n",
    "    return res\n",
    "\n",
    "df_load['secondary_sections_list'] = df_load['secondary_sections'].map(eval_list_with_nan)\n",
    "\n",
    "cross_semester_secondary_sections = df_load\\\n",
    "    .groupby('COURSE_SUBJECT_NAME_NUMBER')\\\n",
    "    [['secondary_sections_list']]\\\n",
    "    .sum()\n",
    "\n",
    "def int_list_to_filled_str_list(l, n_left=3):\n",
    "    return list(set([str(i).zfill(n_left) for i in l]))\n",
    "\n",
    "cross_semester_secondary_sections['secondary_sections_list'] =\\\n",
    "    cross_semester_secondary_sections['secondary_sections_list'].map(int_list_to_filled_str_list)\n",
    "\n",
    "# Add available predictions on a semester basis\n",
    "df_grade_analysis = df_grade_analysis\\\n",
    "    .merge(df_load[['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER', 'secondary_sections']],\n",
    "           how = 'outer', on = ['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER'])\n",
    "\n",
    "# Join generic available LMS secondary sections across semester\n",
    "df_grade_analysis['secondary_sections_cross_semester'] =\\\n",
    "    df_grade_analysis.COURSE_SUBJECT_NAME_NUMBER.map(cross_semester_secondary_sections.to_dict()['secondary_sections_list'])\n",
    "\n",
    "# Fill NA of reference variable for grade filtering with cross semester list\n",
    "df_grade_analysis['secondary_sections'] = df_grade_analysis['secondary_sections'].fillna(df_grade_analysis['secondary_sections_cross_semester'])\n",
    "del df_grade_analysis['secondary_sections_cross_semester']\n",
    "\n",
    "# Omit empty entries, around 5000 entries in Fall 2017 intake\n",
    "df_grade_analysis.dropna(subset=['COURSE_CONTROL_NBR'], inplace=True)\n",
    "\n",
    "# Apply filter of secondary sections directly based on remaining rows after step 1\n",
    "def check_overlap_secondary_sections(s: str, l: list):\n",
    "    if len(s) < 3:\n",
    "        s = s.zfill(3) # There are some section nums which are not padded\n",
    "    return s in l\n",
    "\n",
    "df_grade_analysis = df_grade_analysis[\n",
    "    df_grade_analysis.apply(lambda x: check_overlap_secondary_sections(x.SECTION_NBR, x.secondary_sections), axis=1)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd91de3",
   "metadata": {},
   "source": [
    "# Filter primary section enrollment data (as were courses rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2db119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade = df_grade[df_grade['OFFERING_TYPE_DESC'] == 'Primary'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5287ead",
   "metadata": {},
   "source": [
    "# Check match statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_grade['COURSE_SUBJECT_NAME_NUMBER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183781c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any course ID can not be matched\n",
    "len(set(df_grade['COURSE_SUBJECT_NAME_NUMBER']) - set(df_load['COURSE_SUBJECT_NAME_NUMBER'])) /\\\n",
    "    len(set(df_grade['COURSE_SUBJECT_NAME_NUMBER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca15a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all course, semester pairs based on primary sections\n",
    "dout = df_grade[['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER', 'SECTION_NBR']].drop_duplicates()\n",
    "\n",
    "# LMS completeness statistics -> Add to manuscript maybe\n",
    "for semester in df_load['#SEMESTER_YEAR_NAME_CONCAT'].unique():\n",
    "    courses_with_lms = set(df_load[df_load['#SEMESTER_YEAR_NAME_CONCAT'] == semester].COURSE_SUBJECT_NAME_NUMBER)\n",
    "    courses_taken = set(dout[dout['#SEMESTER_YEAR_NAME_CONCAT'] == semester].COURSE_SUBJECT_NAME_NUMBER)\n",
    "    try:\n",
    "        res = round(len(courses_taken&courses_with_lms)/len(courses_taken),4)*100\n",
    "    except:\n",
    "        res = ''\n",
    "    print(f'In semester {semester}, {res}%')\n",
    "    \n",
    "courses_with_lms = set(df_load.COURSE_SUBJECT_NAME_NUMBER)\n",
    "courses_taken = set(dout.COURSE_SUBJECT_NAME_NUMBER)\n",
    "res = round(len(courses_taken&courses_with_lms)/len(courses_taken),4)*100\n",
    "print(f'In all semesters, {res}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34f4b9",
   "metadata": {},
   "source": [
    "# Aggregate student GPA per semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = False\n",
    "fpath = '../research-data/processed/student-semester-gpas.p'\n",
    "if not skip:\n",
    "    #tmp = df_grade.sample(10000).copy()\n",
    "    #df_gpa = tmp[tmp['GRADE_TYPE_DESC'] == 'Letter Grade']\\\n",
    "    df_gpa = df_grade[(df_grade['GRADE_TYPE_DESC'] == 'Letter Grade') & (df_grade['SNAPSHOT_CODE'] == 'EOT')]\\\n",
    "                    .groupby(['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\\\n",
    "                    [['GRADE_POINTS_NBR', 'STUDENT_CREDIT_HRS_NBR']]\\\n",
    "                    .apply(lambda grades: np.sum(grades['GRADE_POINTS_NBR'] * grades['STUDENT_CREDIT_HRS_NBR']) / np.sum(grades['STUDENT_CREDIT_HRS_NBR']))\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns={0: '#SEMESTER_GPA'})\n",
    "\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(df_gpa, f)\n",
    "else:\n",
    "    with open(fpath, 'rb') as f:\n",
    "        df_gpa = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ced0f",
   "metadata": {},
   "source": [
    "# Aggregate STEM status of student within a semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dc4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dept_stem = {\n",
    "'-': np.nan,\n",
    "'African American Studies': False,\n",
    "'Ag & Env Chem Grad Grp': True,\n",
    "'Ag & Resource Econ & Pol': True,\n",
    "'Anc Hist Med Arc Grad Grp': False,\n",
    "'Ancient Greek & Roman Studies': False,\n",
    "'Anthropology': False,\n",
    "'Applied Sci & Tech Grad Grp': True,\n",
    "'Architecture': True,\n",
    "'Art Practice': False,\n",
    "'Asian Studies Grad Grp': False,\n",
    "'Astronomy': True,\n",
    "'Bioengineering': True,\n",
    "'Bioengineering-UCSF Grad Grp': True,\n",
    "'Biophysics Grad Grp': True,\n",
    "'Biostatistics Grad Grp': True,\n",
    "'Buddhist Studies Grad Grp': False,\n",
    "'Business': False,\n",
    "'Chem & Biomolecular Eng': True,\n",
    "'Chemistry': True,\n",
    "'City & Regional Planning': True,\n",
    "'Civil & Environmental Eng': True,\n",
    "'Classics': False,\n",
    "'College Writing Programs': False,\n",
    "'Comparative Biochem Grad Grp': True,\n",
    "'Comparative Literature': False,\n",
    "'Computational Biology Grad Grp': True,\n",
    "'Critical Theory Grad Grp': False,\n",
    "'Data Science': True,\n",
    "'Demography': False,\n",
    "'Design Innovation': False,\n",
    "'Development Eng Grad Grp': True,\n",
    "'Development Practice Grad Grp': False,\n",
    "'Earth & Planetary Science': True,\n",
    "'East Asian Lang & Culture': False,\n",
    "'Economics': True,\n",
    "'Education': False,\n",
    "'Electrical Eng & Computer Sci': True,\n",
    "'Endocrinology Grad Grp': True,\n",
    "'Energy & Resources Grad Grp': True,\n",
    "'Engineering Joint Programs': True,\n",
    "'Engineering Science': True,\n",
    "'English': False,\n",
    "'Env Sci, Policy, & Mgmt': True,\n",
    "'Environmental Health Sci GG': True,\n",
    "'Epidemiology Grad Grp': True,\n",
    "'Ethnic Studies': False,\n",
    "'European Studies Grad Grp': False,\n",
    "'FPF-African American Studies': False,\n",
    "'FPF-Anc Greek & Roman Studies': False,\n",
    "'FPF-Anthropology': False,\n",
    "'FPF-Art Practice': False,\n",
    "'FPF-Astronomy': True,\n",
    "'FPF-Chemistry': True,\n",
    "'FPF-Classics': False,\n",
    "'FPF-College Writing Program': False,\n",
    "'FPF-Comparative Literature': False,\n",
    "'FPF-Earth & Planetary Science': True,\n",
    "'FPF-English': False,\n",
    "'FPF-Env Sci, Policy, & Mgmt': True,\n",
    "'FPF-Ethnic Studies': False,\n",
    "'FPF-Film & Media': False,\n",
    "'FPF-Gender & Womens Studies': False,\n",
    "'FPF-Geography': False,\n",
    "'FPF-History': False,\n",
    "'FPF-History of Art': False,\n",
    "'FPF-IAS Teaching Program': False,\n",
    "'FPF-Integrative Biology': True,\n",
    "'FPF-Interdisc Social Sci Pgms': False,\n",
    "'FPF-Legal Studies': False,\n",
    "'FPF-Letters & Science': np.nan, # comprises of multiple departments\n",
    "'FPF-Linguistics': False,\n",
    "'FPF-Mathematics': True,\n",
    "'FPF-Molecular & Cell Biology': True,\n",
    "'FPF-Music': False,\n",
    "'FPF-Philosophy': False,\n",
    "'FPF-Political Science': False,\n",
    "'FPF-Psychology': True,\n",
    "'FPF-Rhetoric': False,\n",
    "'FPF-Sociology': False,\n",
    "'FPF-South & SE Asian Studies': False,\n",
    "'FPF-Statistics': True,\n",
    "'FPF-UG Interdisciplinary Stds': False,\n",
    "'Film and Media': False,\n",
    "'Folklore Grad Grp': False,\n",
    "'French': False,\n",
    "'Gender & Womens Studies': False,\n",
    "'Geography': False,\n",
    "'German': False,\n",
    "'Global Metro Std Grad Grp': False,\n",
    "'Global Studies Grad Grp': False,\n",
    "'Grad Division Other Programs': np.nan,\n",
    "'Health & Medical Sci Grad Grp': True,\n",
    "'Health Policy GG': False,\n",
    "'History': False,\n",
    "'History of Art': False,\n",
    "'Industrial Eng & Ops Research': True,\n",
    "'Infectious Diseases & Immun GG': True,\n",
    "'Information': True,\n",
    "'Integrative Biology': True,\n",
    "'Interdisc Social Science Pgms': False,\n",
    "'Interdisciplinary Doctoral Pgm': False,\n",
    "'Italian Studies': False,\n",
    "'JSP Graduate Program': False,\n",
    "'Jewish Studies Program': False,\n",
    "'Journalism': False,\n",
    "'L&S Chemistry': True,\n",
    "'L&S Computer Science': True,\n",
    "'L&S Data Science': True,\n",
    "'L&S Envir Econ & Policy': True,\n",
    "'L&S Legal Studies': False,\n",
    "'L&S Ops Rsch & Mgmt Sci': True,\n",
    "'L&S Public Health': True,\n",
    "'L&S Social Welfare': False,\n",
    "'L&S Undeclared': np.nan,\n",
    "'Landscape Arch & Env Plan': True,\n",
    "'Latin American Studies GG': False,\n",
    "'Law': False,\n",
    "'Linguistics': False,\n",
    "'Logic and Method of Science GG': False,\n",
    "'Materials Science & Eng': True,\n",
    "'Mathematics': True,\n",
    "'Mechanical Engineering': True,\n",
    "'Medieval Studies Program': False,\n",
    "'Metabolic Biology Grad Grp': True,\n",
    "'Microbiology Grad Grp': True,\n",
    "'Middle Eastern Lang & Cultures': False,\n",
    "'Military Affairs Program': False,\n",
    "'Molecular & Cell Biology': True,\n",
    "'Molecular Toxicology Grad Grp': True,\n",
    "'Music': False,\n",
    "'Nano Sci & Eng Grad Grp': True,\n",
    "'Near Eastern Religions GG': False,\n",
    "'Near Eastern Studies': False,\n",
    "'Neuroscience Graduate Program': True,\n",
    "'New Media Grad Grp': False,\n",
    "'Nuclear Engineering': True,\n",
    "'Nutritional Sciences & Tox': True,\n",
    "'Optometry': True,\n",
    "'Other Arts & Humanities Pgms': False,\n",
    "'Other Bio Sciences Pgms': True,\n",
    "'Other Clg of Natural Res Pgms': True,\n",
    "'Other EVCP Programs': False,\n",
    "'Other Env Design Programs': True,\n",
    "'Other Math & Physical Sci Pgms': True,\n",
    "'Other Social Sciences Programs': False,\n",
    "'Performance Studies Grad Grp': False,\n",
    "'Philosophy': False,\n",
    "'Physical Education': False,\n",
    "'Physics': True,\n",
    "'Plant & Microbial Biology': True,\n",
    "'Political Science': False,\n",
    "'Psychology': True,\n",
    "'Public Health': True,\n",
    "'Public Policy': False,\n",
    "'Rangeland & Wildlife Mgmt GG': False,\n",
    "'Rhetoric': False,\n",
    "'Romance Lang & Lit Grad Pgm': False,\n",
    "'Scandinavian': False,\n",
    "'Sci & Tech Stds Grad Grp': True,\n",
    "'Science & Math Educ Grad Grp': True,\n",
    "'Slavic Languages & Literatures': False,\n",
    "'Social Welfare': False,\n",
    "'Sociology': False,\n",
    "'Sociology and Demography GG': False,\n",
    "'South & SE Asian Studies': False,\n",
    "'Spanish & Portuguese': False,\n",
    "'Statistics': True,\n",
    "'Study of Religion Grad Grp': False,\n",
    "'Theater Dance & Perf Stds': False,\n",
    "'UC Education Abroad Program': False,\n",
    "'UCBX-Concurrent Enrollment Dpt': False,\n",
    "'UG Interdisciplinary Studies': False,\n",
    "'Urban Design Grad Grp': False,\n",
    "'Vision Science Grad Grp': True\n",
    "}\n",
    "\n",
    "df_majors = pd.read_csv('../edw_askoski_student_majors_hashed.txt', sep='|')\n",
    "\n",
    "# Filter undeclared entries\n",
    "df_majors =\\\n",
    "    df_majors[df_majors.MAJOR_NAME.map(lambda s: 'undeclared' not in s.lower())]\n",
    "\n",
    "# Get anon IDs that switched major\n",
    "anon_switched = df_majors.groupby('ANON_ID')['MAJOR_NAME'].unique().reset_index().MAJOR_NAME.map(len) > 1\n",
    "anon_switched = pd.DataFrame(anon_switched).reset_index().rename(columns={'index': 'ANON_ID', 'MAJOR_NAME': 'switched_major'})\n",
    "df_majors = df_majors.merge(anon_switched, how='left', on='ANON_ID')\n",
    "\n",
    "# Get first non-undeclared major\n",
    "df_majors = df_majors.drop_duplicates(subset=\"ANON_ID\")\n",
    "\n",
    "# Add STEM status of student\n",
    "df_majors['is_stem_major_student'] =\\\n",
    "    df_majors[['ANON_ID', 'ACADEMIC_DEPARTMENT_NAME']].ACADEMIC_DEPARTMENT_NAME.map(d_dept_stem)\n",
    "join_this = df_majors[['ANON_ID', 'is_stem_major_student', 'switched_major', 'ACADEMIC_DEPARTMENT_NAME', 'ACADEMIC_DIVISION_NAME']]\n",
    "\n",
    "df_grade = df_grade.merge(join_this, how = 'left', on = 'ANON_ID')\n",
    "\n",
    "df_grade['is_stem_course'] = df_grade.CRS_ACADEMIC_DEPT_SHORT_NM.map(d_dept_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade['student_course_stem_match'] = ~(df_grade['is_stem_course'] ^ df_grade['is_stem_major_student'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56620d7",
   "metadata": {},
   "source": [
    "# Aggregate student dropout per semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_difference(a, b):\n",
    "    try:\n",
    "        a = set(a)\n",
    "    except:\n",
    "        a = set() # np.nan\n",
    "    try:\n",
    "        b = set(b)\n",
    "    except:\n",
    "        b = set() # np.nan\n",
    "    return a-b\n",
    "\n",
    "def set_union(a, b):\n",
    "    try:\n",
    "        a = set(a)\n",
    "    except:\n",
    "        a = set() # np.nan\n",
    "    try:\n",
    "        b = set(b)\n",
    "    except:\n",
    "        b = set() # np.nan\n",
    "    return a|b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec321802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any courses that are in CEN but not in EOT should constitute a dropped course\n",
    "\n",
    "skip = False\n",
    "fpath = '../research-data/processed/student-semester-dropoutratios.p'\n",
    "\n",
    "if not skip:\n",
    "    # any courses that are in CEN but not in EOT should constitute a dropped course\n",
    "    courses_cen = df_grade\\\n",
    "                        [df_grade['SNAPSHOT_CODE'] == 'CEN']\\\n",
    "                        .groupby(['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\\\n",
    "                        ['COURSE_SUBJECT_NAME_NUMBER']\\\n",
    "                        .unique()\\\n",
    "                        .reset_index()\\\n",
    "                        .rename(columns={'COURSE_SUBJECT_NAME_NUMBER': 'COURSES_CEN'})\n",
    "\n",
    "    courses_eot = df_grade\\\n",
    "                        [df_grade['SNAPSHOT_CODE'] == 'EOT']\\\n",
    "                        .groupby(['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\\\n",
    "                        ['COURSE_SUBJECT_NAME_NUMBER']\\\n",
    "                        .unique()\\\n",
    "                        .reset_index()\\\n",
    "                        .rename(columns={'COURSE_SUBJECT_NAME_NUMBER': 'COURSES_EOT'})\n",
    "    \n",
    "    # 2020 Spring only has Week 17 and not CEN\n",
    "    courses_week_17 = df_grade\\\n",
    "                        [df_grade['SNAPSHOT_CODE'] == 'Week 17']\\\n",
    "                        .groupby(['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\\\n",
    "                        ['COURSE_SUBJECT_NAME_NUMBER']\\\n",
    "                        .unique()\\\n",
    "                        .reset_index()\\\n",
    "                        .rename(columns={'COURSE_SUBJECT_NAME_NUMBER': 'COURSES_W17'})\n",
    "\n",
    "    df_dropout = courses_cen\\\n",
    "        .merge(courses_eot, how='left', on=['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\\\n",
    "        .merge(courses_week_17, how='left', on=['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\n",
    "\n",
    "    df_dropout['COURSES_DROPPED'] =\\\n",
    "        df_dropout.apply(lambda row: set_difference(row['COURSES_CEN'], row['COURSES_EOT']), axis=1)\n",
    "\n",
    "    df_dropout['COURSES_ALL'] =\\\n",
    "        df_dropout.apply(lambda row: set_union(row['COURSES_CEN'], row['COURSES_EOT']), axis=1)\n",
    "    \n",
    "    df_dropout['COURSES_ALL'] =\\\n",
    "        df_dropout.apply(lambda row: set_union(row['COURSES_ALL'], row['COURSES_W17']), axis=1)\n",
    "\n",
    "    df_dropout['RATIO_COURSES_DROPPED'] = df_dropout['COURSES_DROPPED'].map(len) / df_dropout['COURSES_ALL'].map(len)\n",
    "\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(df_dropout, f)\n",
    "else:\n",
    "    with open(fpath, 'rb') as f:\n",
    "        df_dropout = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621126d6",
   "metadata": {},
   "source": [
    "# Combine load data sets and calculate average load per student, semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55078e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_load = df_grade[['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER', \n",
    "                            'ANON_ID', 'STUDENT_CREDIT_HRS_NBR', 'SNAPSHOT_CODE', \n",
    "                            'is_stem_major_student', 'is_stem_course', 'student_course_stem_match', \n",
    "                            'switched_major', 'OFFERING_TYPE_DESC', 'ACADEMIC_DIVISION_NAME',\n",
    "                            'ACADEMIC_DEPARTMENT_NAME']]\\\n",
    "    .merge(df_load, how='left', on=['#SEMESTER_YEAR_NAME_CONCAT', 'COURSE_SUBJECT_NAME_NUMBER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute by adding average out of all available semesters\n",
    "d_load2impute = df_load\\\n",
    "    .groupby('COURSE_SUBJECT_NAME_NUMBER')\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .set_index('COURSE_SUBJECT_NAME_NUMBER')\\\n",
    "    .to_dict()\\\n",
    "    ['cl_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_load['cl_combined_sem_avg'] = \\\n",
    "    df_student_load.COURSE_SUBJECT_NAME_NUMBER.map(d_load2impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e822c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_load['cl_combined_imputed'] = \\\n",
    "    [a if not pd.isna(a) else b for a, b in zip(df_student_load['cl_combined'], df_student_load['cl_combined_sem_avg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49227608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many courses were imputations based on, on average?\n",
    "nullcourses = set(df_student_load[df_student_load['cl_combined'].isnull()].COURSE_SUBJECT_NAME_NUMBER)\n",
    "df_student_load[df_student_load['COURSE_SUBJECT_NAME_NUMBER'].isin(nullcourses)][['COURSE_SUBJECT_NAME_NUMBER', 'cl_combined']].dropna().drop_duplicates().groupby('COURSE_SUBJECT_NAME_NUMBER').size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_load['cl_combined'].isnull().sum() / df_student_load.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa54000",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = False\n",
    "fpath = '../research-data/processed/student-semester-loads.p'\n",
    "if not skip:\n",
    "    # 2020 Spring only has Week 17 and not CEN\n",
    "    df_student_load_amended = df_student_load.copy()\n",
    "    df_student_load_amended.loc[(df_student_load_amended['#SEMESTER_YEAR_NAME_CONCAT']=='2020 Spring') & \n",
    "                    (df_student_load_amended['SNAPSHOT_CODE']=='Week 17'), 'SNAPSHOT_CODE'] = 'CEN'\n",
    "    df_student_load_semester = df_student_load_amended\\\n",
    "                    [df_student_load_amended['SNAPSHOT_CODE'] == 'CEN']\\\n",
    "                    .groupby(['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])\\\n",
    "                    [['cl_combined', 'cl_combined_imputed', 'STUDENT_CREDIT_HRS_NBR', \n",
    "                      'is_stem_major_student', 'is_stem_course', 'student_course_stem_match', \n",
    "                      'switched_major', 'ACADEMIC_DIVISION_NAME']]\\\n",
    "                    .apply(lambda loads: {'sem_load_credit_hours': np.sum(loads['STUDENT_CREDIT_HRS_NBR']),\n",
    "                                          'sem_load_predicted': np.sum(loads['cl_combined_imputed']),\n",
    "                                          'sem_courses': len(loads['cl_combined_imputed']),\n",
    "                                          'sem_courses_nan_predicted_load': loads['cl_combined'].isna().sum(),\n",
    "                                          'is_stem_major_student': loads['is_stem_major_student'].values[0],\n",
    "                                          'switched_major': loads['switched_major'].values[0],\n",
    "                                          'n_courses': loads.shape[0],\n",
    "                                          'n_stem_courses': loads['is_stem_course'].sum(),\n",
    "                                          'n_courses_stem_match': loads['student_course_stem_match'].sum(),\n",
    "                                          'ratio_courses_stem_match': np.mean(loads['student_course_stem_match']),\n",
    "                                          'ACADEMIC_DIVISION_NAME': loads['ACADEMIC_DIVISION_NAME'].values[0]})\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns={0: '#SEMESTER_LOAD'})\n",
    "    \n",
    "    add_cols = df_student_load_semester['#SEMESTER_LOAD'].apply(pd.Series)\n",
    "    del df_student_load_semester['#SEMESTER_LOAD']\n",
    "    df_student_load_semester = pd.concat([df_student_load_semester, add_cols], axis=1)\n",
    "        \n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(df_student_load_semester, f)\n",
    "else:\n",
    "    with open(fpath, 'rb') as f:\n",
    "        df_student_load_semester = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda55295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio missing predictions without imputation\n",
    "df_student_load_semester['ratio_missing_predictions'] = \\\n",
    "    df_student_load_semester['sem_courses_nan_predicted_load'] / df_student_load_semester['sem_courses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793db94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_load_semester['ratio_missing_predictions'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d49630",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_student_load_semester.ANON_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba1134",
   "metadata": {},
   "source": [
    "# Join semester load to semester GPA and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5693d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df_student_load_semester['#SEMESTER_YEAR_NAME_CONCAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_student_load_semester\\\n",
    "        .merge(df_gpa, how='outer', on=['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b17084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_dropout, how='outer', on=['#SEMESTER_YEAR_NAME_CONCAT', 'ANON_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94921a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN enrollment status variable (Transfer vs non Transfer)\n",
    "df = df\\\n",
    "    .merge(df_cohort_2017[['ANON_ID', 'YEARS_TO_GRADUATION', 'APPLICATION_ENTRY_TYPE']], \n",
    "           how = 'left', on = 'ANON_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_code = {\n",
    "    'NEW FRESHMEN': 'Non-Transfer',\n",
    "    'ADVANCED STANDING': 'Transfer',\n",
    "    'SECOND BACHELOR?S DEGREE': 'Non-Transfer'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fac842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_transfer'] = df.APPLICATION_ENTRY_TYPE.map(d_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568623b0",
   "metadata": {},
   "source": [
    "# Add semester count and program retention variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semester_count(s):\n",
    "    if s=='2017 Fall': return 1\n",
    "    elif s=='2018 Spring': return 2\n",
    "    elif s=='2018 Fall': return 3\n",
    "    elif s=='2019 Spring': return 4\n",
    "    elif s=='2019 Fall': return 5\n",
    "    elif s=='2020 Spring': return 6\n",
    "    elif s=='2020 Fall': return 7\n",
    "    elif s=='2021 Spring': return 8\n",
    "    else: return ''\n",
    "\n",
    "df['semester_count'] = df['#SEMESTER_YEAR_NAME_CONCAT'].map(get_semester_count)\n",
    "\n",
    "df['semester_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521067be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_sem_count(row):\n",
    "    if row['is_transfer'] == 'Transfer':\n",
    "        return row['semester_count'] + 4\n",
    "    else:\n",
    "        return row['semester_count'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841647a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['semester_count_real'] = df.apply(get_true_sem_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_dropped_program(row):\n",
    "    \"\"\"\n",
    "    dropout = 2 consecutive years of non-enrollment\n",
    "    \"\"\"\n",
    "    if row['RETENTION_FLAG_AFTER_1_YEARS'] == 'N' and row['RETENTION_FLAG_AFTER_2_YEARS'] == 'N':\n",
    "        return True\n",
    "    elif row['RETENTION_FLAG_AFTER_2_YEARS'] == 'N' and row['RETENTION_FLAG_AFTER_3_YEARS'] == 'N':\n",
    "        return True\n",
    "    elif row['RETENTION_FLAG_AFTER_3_YEARS'] == 'N' and row['RETENTION_FLAG_AFTER_4_YEARS'] == 'N':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a679de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropout_year(row):\n",
    "    \"\"\"\n",
    "    dropout = 2 consecutive years of non-enrollment\n",
    "    \"\"\"\n",
    "    if row['RETENTION_FLAG_AFTER_1_YEARS'] == 'N' and row['RETENTION_FLAG_AFTER_2_YEARS'] == 'N':\n",
    "        return 1\n",
    "    elif row['RETENTION_FLAG_AFTER_2_YEARS'] == 'N' and row['RETENTION_FLAG_AFTER_3_YEARS'] == 'N':\n",
    "        return 2\n",
    "    elif row['RETENTION_FLAG_AFTER_3_YEARS'] == 'N' and row['RETENTION_FLAG_AFTER_4_YEARS'] == 'N':\n",
    "        return 3\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = pd.read_csv('../edw_askoski_student_cohorts_hashed.txt', sep='|')\n",
    "\n",
    "df_cohort['student_dropped_program'] = df_cohort.apply(get_student_dropped_program, axis=1)\n",
    "\n",
    "df_cohort['dropout_year'] = df_cohort.apply(get_dropout_year, axis=1)\n",
    "\n",
    "df_cohort['dropout_semester_estimate'] = df_cohort['dropout_year']*2\n",
    "\n",
    "df = df.merge(df_cohort[['ANON_ID', 'student_dropped_program', 'dropout_year', 'dropout_semester_estimate']],\n",
    "              how='left', on='ANON_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ebe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graduated_on_time(row):\n",
    "    \n",
    "    if row['is_transfer'] == 'Transfer':\n",
    "        if row['YEARS_TO_GRADUATION'] <= 2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if row['YEARS_TO_GRADUATION'] <= 4:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4bc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['graduated_on_time'] = df.apply(get_graduated_on_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b2d4c",
   "metadata": {},
   "source": [
    "# Course plot credit hours over predicted, colored by dropout composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_student_load[(df_student_load['SNAPSHOT_CODE']=='EOT') & (df_student_load['OFFERING_TYPE_DESC']=='Primary')]\\\n",
    "    [['ANON_ID', 'COURSE_SUBJECT_NAME_NUMBER', 'STUDENT_CREDIT_HRS_NBR', 'cl_combined_imputed', 'is_stem_course',\n",
    "      'ACADEMIC_DEPARTMENT_NAME', 'ACADEMIC_DIVISION_NAME']]\\\n",
    "    .merge(df[['ANON_ID', 'graduated_on_time', 'student_dropped_program']], how='left', on='ANON_ID')\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('COURSE_SUBJECT_NAME_NUMBER')\\\n",
    "    .agg({'STUDENT_CREDIT_HRS_NBR':'max', \n",
    "          'cl_combined_imputed':'mean', \n",
    "          'graduated_on_time':'mean', \n",
    "          'student_dropped_program': 'mean',\n",
    "          'is_stem_course': 'max', \n",
    "          'ACADEMIC_DEPARTMENT_NAME': 'unique',\n",
    "          'ACADEMIC_DIVISION_NAME': 'unique'})\\\n",
    "    .reset_index()\\\n",
    "    .dropna()\n",
    "df_plot['ACADEMIC_DEPARTMENT_NAME'] = df_plot['ACADEMIC_DEPARTMENT_NAME'].map(lambda x: x[0])\n",
    "df_plot['ACADEMIC_DIVISION_NAME'] = df_plot['ACADEMIC_DIVISION_NAME'].map(lambda x: x[0])\n",
    "df_plot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_vector(v):\n",
    "    mx = np.mean(v)\n",
    "    sdx = np.std(v)\n",
    "    return [(x-mx)/sdx for x in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot['ch_z'] = standardize_vector(df_plot['STUDENT_CREDIT_HRS_NBR'])\n",
    "df_plot['cl_z'] = standardize_vector(df_plot['cl_combined_imputed'])\n",
    "df_plot['diff_cl_ch'] = df_plot['cl_z'] - df_plot['ch_z'] #COURSE LOAD DISCREPANCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_error(v, return_twice=True): \n",
    "    ans = np.std(v, ddof=1) / np.sqrt(np.size(v))\n",
    "    return 2*ans if return_twice else ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot\\\n",
    "    .groupby('is_stem_course')\\\n",
    "    [['diff_cl_ch']]\\\n",
    "    .agg([np.mean, get_standard_error])\\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5409e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import researchpy as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary, results = rp.ttest(group1= df_plot['diff_cl_ch'][df_plot['is_stem_course']], group1_name= \"STEM\",\n",
    "                            group2= df_plot['diff_cl_ch'][~df_plot['is_stem_course']], group2_name= \"Non-STEM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(summary, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "fig = plt.figure(figsize=(16, 6), dpi=120)\n",
    "df_plot['Top 10% Dropout Course'] =\\\n",
    "    df_plot['student_dropped_program'] > np.nanquantile(df_plot['student_dropped_program'], 0.9)\n",
    "\n",
    "ax = sns.violinplot(x=\"is_stem_course\", y=\"diff_cl_ch\", hue='Top 10% Dropout Course', data=df_plot, split=True)\n",
    "ax.set(ylim=(-6.5, None))\n",
    "ax.legend(loc='upper center', title='Top 10% Dropout Course')\n",
    "\n",
    "ax.set_xlabel('Course is a STEM Course')\n",
    "ax.set_ylabel('Predicted Load - Credit Hours ($\\Delta_{SD}$)')\n",
    "\n",
    "plt.savefig('../plots/stem-non-stem-load-discrepancies-violin.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f21d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df_plot[df_plot['diff_cl_ch']>2].COURSE_SUBJECT_NAME_NUMBER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b79fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What features contributed to high discrepancy?\n",
    "\n",
    "# Which features were most correlated with discrepancy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features based on CID\n",
    "fs = [\n",
    "    '../research-data/processed/course-features-2017 Spring.csv',\n",
    "    '../research-data/processed/course-features-2017 Fall.csv',\n",
    "    '../research-data/processed/course-features-2018 Spring.csv',\n",
    "    '../research-data/processed/course-features-2018 Fall.csv',\n",
    "    '../research-data/processed/course-features-2019 Spring.csv',\n",
    "    '../research-data/processed/course-features-2019 Fall.csv',\n",
    "    '../research-data/processed/course-features-2020 Spring.csv',\n",
    "    '../research-data/processed/course-features-2020 Fall.csv',\n",
    "    '../research-data/processed/course-features-2021 Spring.csv'\n",
    "]\n",
    "\n",
    "remaining_cids = set(df_plot.COURSE_SUBJECT_NAME_NUMBER)\n",
    "dfs = []\n",
    "for f in fs[-1::-1]: # recent first\n",
    "    tmp = pd.read_csv(f)\n",
    "    dfs.append(tmp[tmp['course_name_number'].isin(remaining_cids)].copy())\n",
    "    remaining_cids -= set(tmp.course_name_number)\n",
    "    print(f'{len(remaining_cids)} courses remaining...')\n",
    "    \n",
    "course_features = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_2 = df_plot.merge(course_features, how='left', \n",
    "                          left_on='COURSE_SUBJECT_NAME_NUMBER', right_on='course_name_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97308332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import partial_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run partial correlations\n",
    "def r_to_z(r):\n",
    "    return math.log((1 + r) / (1 - r)) / 2.0\n",
    "\n",
    "def z_to_r(z):\n",
    "    e = math.exp(2 * z)\n",
    "    return((e - 1) / (e + 1))\n",
    "\n",
    "def r_confidence_interval(r, n, alpha=0.05):\n",
    "    z = r_to_z(r)\n",
    "    se = 1.0 / math.sqrt(n - 3)\n",
    "    z_crit = scipy.stats.norm.ppf(1 - alpha/2)  # 2-tailed z critical value\n",
    "\n",
    "    lo = z - z_crit * se\n",
    "    hi = z + z_crit * se\n",
    "\n",
    "    # Return a sequence\n",
    "    return (z_to_r(lo), z_to_r(hi))\n",
    "\n",
    "def correlation_pairwise_complete(series1, series2):\n",
    "    x, y = series1.values, series2.values\n",
    "    nas = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "    corr = scipy.stats.pearsonr(x[~nas], y[~nas])\n",
    "    n = len(x[~nas])\n",
    "    ci_low, ci_high = r_confidence_interval(corr[0], n, alpha=0.05)\n",
    "    return corr, n, ci_low, ci_high\n",
    "\n",
    "def partial_correlation_pairwise_complete(df: pd.DataFrame, series1: str, series2: str, controlseries: str):\n",
    "    \n",
    "    return partial_corr(data=df, x=series1, y=series2, covar=[controlseries], method='pearson')\n",
    "\n",
    "def get_correlation_results_disc(filter_2sd=False):\n",
    "    \n",
    "    if filter_2sd:\n",
    "        df_plot_3 = df_plot_2[df_plot_2['diff_cl_ch']>2].copy()\n",
    "    else:\n",
    "        df_plot_3 = df_plot_2.copy()\n",
    "    \n",
    "    feats, ns, cors, dfs, ps, ci_lows, ci_highs = [], [] ,[], [], [], [], []\n",
    "    for col in set(tmp.columns) - {'course_name_number', 'section_num', 'secondary_section_number', 'all_section_numbers'}:\n",
    "        try:\n",
    "            (r, p), n, ci_low, ci_high = correlation_pairwise_complete(df_plot_3['diff_cl_ch'], df_plot_3[col])\n",
    "        except:\n",
    "            continue\n",
    "        feats.append(col)\n",
    "        ns.append(n)\n",
    "        cors.append(r)\n",
    "        dfs.append(n-2)\n",
    "        ps.append(p)\n",
    "        ci_lows.append(ci_low)\n",
    "        ci_highs.append(ci_high)\n",
    "\n",
    "    correlations = pd.DataFrame({\n",
    "        'x': feats,\n",
    "        'n': ns, \n",
    "        'r': [round(cor, 2) for cor in cors],\n",
    "        'ci_low': [round(cor, 2) for cor in ci_lows],\n",
    "        'ci_high': [round(cor, 2) for cor in ci_highs],\n",
    "        'df': dfs,\n",
    "        'p': [round(p, 3) for p in ps]\n",
    "    }).sort_values(by='r', key=lambda x: -np.abs(x))\n",
    "\n",
    "    correlations['is_c2v_var'] = correlations['x'].map(lambda s: 'c2v' in s)\n",
    "    \n",
    "    correlations['ci'] = correlations.apply(lambda row: '[' + str(row['ci_low']) + ', ' + str(row['ci_high']) + ']', axis=1)\n",
    "\n",
    "    display(correlations[correlations['is_c2v_var']].head(15).sort_values(by='r', ascending=False))\n",
    "\n",
    "    display(correlations[~correlations['is_c2v_var']].head(15).sort_values(by='r', ascending=False))\n",
    "    return correlations\n",
    "\n",
    "def get_partial_correlation_results_disc(filter_2sd=False):\n",
    "    \n",
    "    if filter_2sd:\n",
    "        df_plot_3 = df_plot_2[df_plot_2['diff_cl_ch']>2].copy()\n",
    "    else:\n",
    "        df_plot_3 = df_plot_2.copy()\n",
    "    \n",
    "    res = []\n",
    "    for col in set(df_plot_3.columns) - {'course_name_number', 'section_num', 'secondary_section_number', 'all_section_numbers'}:\n",
    "        try:\n",
    "            tmp = partial_correlation_pairwise_complete(df_plot_3, col, 'diff_cl_ch', 'ch_z')\n",
    "            tmp['x'] = col\n",
    "            res.append(tmp)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    ans = pd.concat(res)\n",
    "\n",
    "    ans['is_c2v_var'] = ans['x'].map(lambda s: 'c2v' in s)\n",
    "    \n",
    "    ans['p-val'] = ans['p-val'].map(lambda x: round(x, 3))\n",
    "    \n",
    "    ans['r_abs'] = ans['r'].map(lambda x: np.abs(x))\n",
    "    \n",
    "    #display(ans[~ans['is_c2v_var']].head(15).sort_values(by='r', ascending=False))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cors1 = get_partial_correlation_results_disc()\n",
    "print('##################################')\n",
    "cors2 = get_partial_correlation_results_disc(filter_2sd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = cors1[~cors1['is_c2v_var']].sort_values(by='r_abs', ascending=False)\n",
    "tab = tab[~tab['x'].isin(['STUDENT_CREDIT_HRS_NBR', 'cl_combined_imputed', 'cl_z', 'n_credit_hours'])]\n",
    "tab.head(15).sort_values(by='r', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975625bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cors1[cors1['x'].map(lambda s: 'prereq' in s and 'c2v' not in s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2v_cors = cors1[(~cors1['is_c2v_var']) & (cors1['x']!='cl_z') & (cors1['x']!='STUDENT_CREDIT_HRS_NBR') & (cors1['x']!='cl_combined_imputed')].sort_values(by='r_abs', ascending=False).head(15)\n",
    "\n",
    "c2v_cors.sort_values(by='r', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2v_cors = cors1[(~cors1['is_c2v_var']) & (cors1['x']!='cl_z') & (cors1['x']!='STUDENT_CREDIT_HRS_NBR') & (cors1['x']!='cl_combined_imputed')].sort_values(by='r_abs', ascending=False).head(15)\\\n",
    "    .merge(cors2.add_suffix('_2sd'), how='left', left_on='x', right_on='x_2sd')\n",
    "\n",
    "c2v_cors['2sd_robust'] = c2v_cors['p-val_2sd'].map(lambda x: x<.05)\n",
    "c2v_cors.sort_values(by='r', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e705ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_2.student_to_instructional_staff_ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_2[df_plot_2['diff_cl_ch']>4].student_to_instructional_staff_ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial correlation with boostrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f43f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple R2 with boostrap c2v vs. c2v prereqs, controlling for credit hours\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_r2_mr(df, c2v_prereq=False, return_model=False, include_credit_hours_only=False):\n",
    "    \n",
    "    tmp = df.copy()\n",
    "    \n",
    "    if c2v_prereq:\n",
    "        tmp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        tmp.dropna(inplace=True, subset=[f'c2v_prereq_avg_{i}' for i in range(1, 300+1)] + ['ch_z'])\n",
    "    \n",
    "    X_cols = [f'c2v_prereq_avg_{i}' for i in range(1, 300+1)] if c2v_prereq else [f'c2v_{i}' for i in range(1, 300+1)]\n",
    "    X_cols += ['ch_z']\n",
    "    \n",
    "    if include_credit_hours_only: \n",
    "        X_cols = ['ch_z']\n",
    "    \n",
    "    X = tmp[X_cols]\n",
    "    y = tmp['diff_cl_ch']\n",
    "            \n",
    "    m = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return m if return_model else m.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 bootstrap, c2v course\n",
    "n = 10 # reduced to 10 to run whole notebook faster\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    inds = np.random.randint(0, len(df_plot_2), size=len(df_plot_2))\n",
    "    res.append(get_r2_mr(df_plot_2.iloc[inds], c2v_prereq=False, return_model=False))\n",
    "print('C2V prereqs')\n",
    "print(f\"M = {np.mean(res)}, 95% CI = [{np.quantile(res, 0.025)}, {np.quantile(res, 0.975)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 bootstrap, c2v prereqs\n",
    "n = 10\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    inds = np.random.randint(0, len(df_plot_2), size=len(df_plot_2))\n",
    "    res.append(get_r2_mr(df_plot_2.iloc[inds], c2v_prereq=True, return_model=False))\n",
    "print('C2V prereqs')\n",
    "print(f\"M = {np.mean(res)}, 95% CI = [{np.quantile(res, 0.025)}, {np.quantile(res, 0.975)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 bootstrap, contribution of credit hours only\n",
    "n = 10\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    inds = np.random.randint(0, len(df_plot_2), size=len(df_plot_2))\n",
    "    res.append(get_r2_mr(df_plot_2.iloc[inds], c2v_prereq=False, return_model=False, include_credit_hours_only=True))\n",
    "print('C2V prereqs')\n",
    "print(f\"M = {np.mean(res)}, 95% CI = [{np.quantile(res, 0.025)}, {np.quantile(res, 0.975)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just with top courses\n",
    "df_plot_3 = df_plot_2[df_plot_2['diff_cl_ch']>2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d91244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 bootstrap, c2v course\n",
    "n = 10\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    inds = np.random.randint(0, len(df_plot_3), size=len(df_plot_3))\n",
    "    res.append(get_r2_mr(df_plot_3.iloc[inds], c2v_prereq=False, return_model=False))\n",
    "print('C2V prereqs')\n",
    "print(f\"M = {np.mean(res)}, 95% CI = [{np.quantile(res, 0.025)}, {np.quantile(res, 0.975)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a03f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 bootstrap, c2v prereqs\n",
    "n = 10 \n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    inds = np.random.randint(0, len(df_plot_3), size=len(df_plot_3))\n",
    "    res.append(get_r2_mr(df_plot_3.iloc[inds], c2v_prereq=True, return_model=False))\n",
    "print('C2V prereqs')\n",
    "print(f\"M = {np.mean(res)}, 95% CI = [{np.quantile(res, 0.025)}, {np.quantile(res, 0.975)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310cc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 bootstrap, contribution of credit hours only\n",
    "n = 10\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    inds = np.random.randint(0, len(df_plot_3), size=len(df_plot_3))\n",
    "    res.append(get_r2_mr(df_plot_3.iloc[inds], c2v_prereq=False, return_model=False, include_credit_hours_only=True))\n",
    "print('C2V prereqs')\n",
    "print(f\"M = {np.mean(res)}, 95% CI = [{np.quantile(res, 0.025)}, {np.quantile(res, 0.975)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8055ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequsitie adjustment\n",
    "\n",
    "# Compute how much predicted load is in one prereq -> regression of cl over n prereqs\n",
    "\n",
    "# Multiply by modal number of satisfied prereqs\n",
    "\n",
    "# Convert into credit hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d166b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "fs = [\n",
    "    '../research-data/processed/course-features-2017 Spring.csv',\n",
    "    '../research-data/processed/course-features-2017 Fall.csv',\n",
    "    '../research-data/processed/course-features-2018 Spring.csv',\n",
    "    '../research-data/processed/course-features-2018 Fall.csv',\n",
    "    '../research-data/processed/course-features-2019 Spring.csv',\n",
    "    '../research-data/processed/course-features-2019 Fall.csv',\n",
    "    '../research-data/processed/course-features-2020 Spring.csv',\n",
    "    '../research-data/processed/course-features-2020 Fall.csv',\n",
    "    '../research-data/processed/course-features-2021 Spring.csv'\n",
    "]\n",
    "\n",
    "# Sems\n",
    "refs = [f.split('-')[-1].split('.')[0] for f in fs]\n",
    "\n",
    "dfs = [] \n",
    "for f, sem in zip(fs, refs):\n",
    "    tmp = pd.read_csv(f)\n",
    "    tmp = tmp[['course_name_number', 'n_prereqs', 'n_satisfied_prereqs_all_past_semesters']]\n",
    "    tmp = tmp.drop_duplicates()\n",
    "    tmp = tmp.rename(columns = {'course_name_number': 'COURSE_SUBJECT_NAME_NUMBER'})\n",
    "    dfs.append(tmp)\n",
    "df_prereqs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_2 = df_plot[df_plot['diff_cl_ch'] > 5].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_2 = df_plot[df_plot['is_stem_course']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_2 = df_plot[df_plot['diff_cl_ch'] > 3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prereqs_load = df_plot_2[['COURSE_SUBJECT_NAME_NUMBER', 'cl_combined_imputed']]\\\n",
    "    .merge(df_prereqs, on='COURSE_SUBJECT_NAME_NUMBER', how='left')\\\n",
    "    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "tmp = df_prereqs_load.copy()\n",
    "#tmp['cl_combined_imputed'] = np.log(tmp['cl_combined_imputed'])\n",
    "#tmp['n_prereqs'] = np.log(tmp['n_prereqs'])\n",
    "\n",
    "result = sm.ols(formula=\"cl_combined_imputed ~ n_satisfied_prereqs_all_past_semesters\", data=tmp).fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prereqs_load['n_satisfied_prereqs_all_past_semesters'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd803c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three credit hour course -> 2.62 analytics units\n",
    "2.62/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scale adjustment to credit hour scale\n",
    "(0.446950*0.7802066342154884)/0.8733333333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc93877",
   "metadata": {},
   "source": [
    "# Load distribution longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259883d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3 Freshman vs. advanced part 1\n",
    "df_sem_load_plot = df.groupby(['semester_count', 'is_stem_major_student'])['sem_load_credit_hours'].agg([np.mean, get_standard_error]).reset_index()\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 24})\n",
    "fig,ax = plt.subplots(figsize=(14,8), dpi=180)\n",
    "lvls = df_sem_load_plot.is_stem_major_student.unique()\n",
    "first = True\n",
    "for i in lvls:\n",
    "    ax.errorbar(x = df_sem_load_plot[df_sem_load_plot['is_stem_major_student']==i][\"semester_count\"],\n",
    "                y=df_sem_load_plot[df_sem_load_plot['is_stem_major_student']==i][\"mean\"], \n",
    "                yerr=df_sem_load_plot[df_sem_load_plot['is_stem_major_student']==i][\"get_standard_error\"],\n",
    "                label=i, linestyle='dashed' if not first else 'solid')\n",
    "    first = False\n",
    "ax.legend()\n",
    "ax.set_xlabel('Semester Count')\n",
    "ax.set_ylabel('Average Credit Hour Load')\n",
    "ax.legend(labels=['Non-STEM Major Students', 'STEM Major Students'])\n",
    "\n",
    "fig.savefig('../plots/avg-credit-load-stem-non-stem.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ef3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3 Freshman vs. advanced part 1\n",
    "df_sem_load_plot = df.groupby(['semester_count', 'is_stem_major_student'])['sem_load_predicted'].agg([np.mean, get_standard_error]).reset_index()\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 24})\n",
    "fig, ax = plt.subplots(figsize=(14,8), dpi=180)\n",
    "lvls = df_sem_load_plot.is_stem_major_student.unique()\n",
    "first = True\n",
    "for i in lvls:\n",
    "    ax.errorbar(x = df_sem_load_plot[df_sem_load_plot['is_stem_major_student']==i][\"semester_count\"],\n",
    "                y=df_sem_load_plot[df_sem_load_plot['is_stem_major_student']==i][\"mean\"], \n",
    "                yerr=df_sem_load_plot[df_sem_load_plot['is_stem_major_student']==i][\"get_standard_error\"],\n",
    "                label=i, linestyle='dashed' if not first else 'solid')\n",
    "    first = False\n",
    "ax.legend()\n",
    "ax.set_xlabel('Semester Count')\n",
    "ax.set_ylabel('Average Predicted Course Load')\n",
    "ax.legend(labels=['Non-STEM Major Students', 'STEM Major Students'])\n",
    "\n",
    "ax.yaxis.set_ticks(np.arange(10.25, 12.75, 0.25))\n",
    "\n",
    "fig.savefig('../plots/avg-pred-load-stem-non-stem.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b66bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3 Freshman vs. advanced part 1\n",
    "df_sem_load_plot = df.groupby(['semester_count', 'is_transfer'])['sem_load_predicted'].agg([np.mean, get_standard_error]).reset_index()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(14,8))\n",
    "lvls = df_sem_load_plot.is_transfer.unique()\n",
    "for i in lvls:\n",
    "    ax.errorbar(x = df_sem_load_plot[df_sem_load_plot['is_transfer']==i][\"semester_count\"],\n",
    "                y=df_sem_load_plot[df_sem_load_plot['is_transfer']==i][\"mean\"], \n",
    "                yerr=df_sem_load_plot[df_sem_load_plot['is_transfer']==i][\"get_standard_error\"],label=i)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_vector(v):\n",
    "    mx = np.mean(v)\n",
    "    sdx = np.std(v)\n",
    "    return [(x-mx)/sdx for x in v]\n",
    "\n",
    "df['sem_load_predicted_z'] = standardize_vector(df['sem_load_predicted'])\n",
    "df['sem_load_credit_hours_z'] = standardize_vector(df['sem_load_credit_hours'])\n",
    "df['sem_load_diff_pred_minus_ch'] = df['sem_load_predicted_z'] - df['sem_load_credit_hours_z']\n",
    "\n",
    "df.sort_values(by='sem_load_diff_pred_minus_ch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to conduct likelihood-ratio tests in R\n",
    "df.to_csv('../research-data/processed/lak23wlsample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed741854",
   "metadata": {},
   "source": [
    "## Logistic regression model inferences dropout and on-time graduation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f92274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "tmp = df[['sem_load_credit_hours', 'sem_load_predicted', 'student_dropped_program']].dropna().copy()\n",
    "Xtrain = tmp[['sem_load_credit_hours', 'sem_load_predicted']]\n",
    "ytrain = tmp[['student_dropped_program']]\n",
    "print(tmp.shape)\n",
    "    \n",
    "# building the model and fitting the data\n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit()\n",
    "\n",
    "print(log_reg.summary())\n",
    "\n",
    "y = np.array(Xtrain['sem_load_credit_hours'])\n",
    "x = np.array(Xtrain['sem_load_predicted'])\n",
    "z = np.array(ytrain['student_dropped_program'])\n",
    "\n",
    "x_pred = np.linspace(0, 35, 100)      # range of porosity values\n",
    "y_pred = np.linspace(0, 35, 100)   # range of VR values\n",
    "xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "model_viz = np.array([yy_pred.flatten(), xx_pred.flatten()]).T\n",
    "predicted = log_reg.predict(model_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f623ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_xcp(q=.5):\n",
    "    \"\"\"\n",
    "    Get predictions based on a particular credit hour quantile.\n",
    "    x -> predicted, fix -> credit hour semester load\n",
    "    Validated\n",
    "    \"\"\"\n",
    "    x_pred = np.linspace(0, 30, 100)      # predicted load\n",
    "    y_pred = np.array([np.quantile(Xtrain['sem_load_credit_hours'], q)]*100)      # fixed credit hours\n",
    "    xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "    model_viz = np.array([yy_pred.flatten(), xx_pred.flatten()]).T\n",
    "    predicted = log_reg.predict(model_viz)\n",
    "    x_plot = model_viz[:,1] # predicted load\n",
    "    y_plot = predicted\n",
    "    return x_plot, y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69829ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_xch(q=.5):\n",
    "    \"\"\"\n",
    "    Get predictions based on a particular credit hour quantile.\n",
    "    x -> credit hours, fix -> predicted load\n",
    "    \"\"\"\n",
    "    y_pred = np.linspace(0, 30, 100)      # credit hour load\n",
    "    x_pred = np.array([np.quantile(Xtrain['sem_load_predicted'], q)]*100)      # fixed predicted load\n",
    "    #xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "    model_viz = np.array([y_pred.flatten(), x_pred.flatten()]).T\n",
    "    predicted = log_reg.predict(model_viz)\n",
    "    x_plot = model_viz[:,0] # credit hour load\n",
    "    y_plot = predicted\n",
    "    return x_plot, y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56862a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.linspace(0, 30, 100)      # credit hour load\n",
    "x_pred = np.array([np.quantile(Xtrain['sem_load_predicted'], .5)]*100)      # fixed predicted load\n",
    "#xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "model_viz = np.array([y_pred.flatten(), x_pred.flatten()]).T\n",
    "predicted = log_reg.predict(model_viz)\n",
    "x_plot = model_viz[:,0] # credit hour load\n",
    "y_plot = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d901960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dropout model space model 2d by median split\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "x_plot, _ = get_predictions_xcp()\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "CB_color_cycle.reverse()\n",
    "CB_color_cycle[:len(x_plot)]\n",
    "the_range = list(range(10, 100, 20))\n",
    "for q, c in zip(the_range, CB_color_cycle):\n",
    "    _, y_plot = get_predictions_xcp(q/100)\n",
    "    ch = int(np.quantile(Xtrain['sem_load_credit_hours'], q/100))\n",
    "    plt.annotate(f\"Q{q} ({ch} CH)\", (31, max(y_plot)), size=12)\n",
    "    plt.scatter(x_plot, y_plot, color=c)\n",
    "plt.xlabel('Predicted Semester Load')\n",
    "plt.ylabel('P(Dropout)')\n",
    "plt.xlim(0, 38)\n",
    "plt.yticks([0.025, 0.05, 0.075, 0.1, 0.125])\n",
    "plt.savefig('../plots/predicted-marginal-dropout.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Space On-Time Graduation\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "tmp = df[['sem_load_credit_hours', 'sem_load_predicted', 'graduated_on_time']].dropna().copy()\n",
    "tmp['graduated_on_time'] = tmp['graduated_on_time'].map(lambda x: 0 if x == True else 1)\n",
    "Xtrain = tmp[['sem_load_credit_hours', 'sem_load_predicted']]\n",
    "ytrain = tmp[['graduated_on_time']]\n",
    "print(tmp.shape)\n",
    "\n",
    "# building the model and fitting the data\n",
    "log_reg = smf.logit(formula='graduated_on_time ~ sem_load_predicted + sem_load_credit_hours + sem_load_predicted:sem_load_credit_hours', data=tmp).fit()\n",
    "\n",
    "print(log_reg.summary())\n",
    "\n",
    "y = np.array(Xtrain['sem_load_credit_hours'])\n",
    "x = np.array(Xtrain['sem_load_predicted'])\n",
    "z = np.array(ytrain['graduated_on_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e876f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_xch(q=.5):\n",
    "    \"\"\"\n",
    "    Get predictions based on a particular credit hour quantile.\n",
    "    x -> credit hours, fix -> predicted load\n",
    "    \"\"\"\n",
    "    y_pred = np.linspace(0, 30, 100)      # credit hour load\n",
    "    x_pred = np.array([np.quantile(Xtrain['sem_load_predicted'], q)]*100)      # fixed predicted load\n",
    "    #xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "    model_viz = np.array([y_pred.flatten(), x_pred.flatten()]).T\n",
    "    predicted = np.array(log_reg.predict(pd.DataFrame({'sem_load_credit_hours': y_pred.flatten(), 'sem_load_predicted': x_pred.flatten()})))\n",
    "    x_plot = model_viz[:,0] # credit hour load\n",
    "    y_plot = predicted\n",
    "    return x_plot, y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8fa58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_xcp(q=.5):\n",
    "    \"\"\"\n",
    "    Get predictions based on a particular credit hour quantile.\n",
    "    x -> predicted, fix -> credit hour semester load\n",
    "    Validated\n",
    "    \"\"\"\n",
    "    x_pred = np.linspace(0, 30, 100)      # predicted load\n",
    "    y_pred = np.array([np.quantile(Xtrain['sem_load_credit_hours'], q)]*100)      # fixed credit hours\n",
    "    xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "    model_viz = np.array([yy_pred.flatten(), xx_pred.flatten()]).T\n",
    "    predicted = np.array(log_reg.predict(pd.DataFrame({'sem_load_credit_hours': yy_pred.flatten(), 'sem_load_predicted': xx_pred.flatten()})))\n",
    "    x_plot = model_viz[:,1] # predicted load\n",
    "    y_plot = predicted\n",
    "    return x_plot, y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe73e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dropout model space model 2d by median split\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "x_plot, _ = get_predictions_xch()\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "CB_color_cycle.reverse()\n",
    "CB_color_cycle[:len(x_plot)]\n",
    "the_range = list(range(10, 100, 10))\n",
    "for q, c in zip(the_range, CB_color_cycle):\n",
    "    _, y_plot = get_predictions_xch(q/100)\n",
    "    plt.scatter(x_plot, y_plot, color=c)\n",
    "plt.xlabel('Credit Hour Semester Load')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52970af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dropout model space model 2d by median split\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "x_plot, _ = get_predictions_xcp()\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "CB_color_cycle.reverse()\n",
    "CB_color_cycle[:len(x_plot)]\n",
    "the_range = list(range(10, 100, 20))\n",
    "for q, c in zip(the_range, CB_color_cycle):\n",
    "    _, y_plot = get_predictions_xcp(q/100)\n",
    "    ch = int(np.quantile(Xtrain['sem_load_credit_hours'], q/100))\n",
    "    plt.annotate(f\"Q{q} ({ch} CH)\", (-7, min(y_plot)), size=12)\n",
    "    plt.scatter(x_plot, y_plot, color=c)\n",
    "plt.xlabel('Predicted Semester Load')\n",
    "plt.ylabel('P(Delayed Graduation)')\n",
    "plt.xlim(-7.5, 30)\n",
    "plt.yticks([0.1, 0.15, 0.2, 0.25, 0.3, 0.35])\n",
    "plt.savefig('../plots/predicted-marginal-delay.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defe863",
   "metadata": {},
   "source": [
    "## Empirically derived cutoff for credit hour load or semester load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model and fitting the data\n",
    "log_reg = smf.logit(formula='graduated_on_time ~ sem_load_predicted', data=tmp).fit()\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_ch_median_cl = df_plot[df_plot['STUDENT_CREDIT_HRS_NBR']==3].cl_combined_imputed.median()\n",
    "3*(25/three_ch_median_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_ch_median_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40147a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(12568/(45757+12568), 4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87077631",
   "metadata": {},
   "source": [
    "## Fitted model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ROC bootstrap\n",
    "n = 1000\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    \n",
    "    inds = np.random.randint(0, len(Xtrain), size=len(Xtrain))\n",
    "    xt = Xtrain.iloc[inds]\n",
    "    yt = ytrain.iloc[inds]\n",
    "\n",
    "    res.append(roc_auc_score(yt, log_reg.predict(xt)))\n",
    "\n",
    "print(f'M = {np.mean(res)} , 95% CI = [{np.quantile(res, 0.025)} , {np.quantile(res, 0.975)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca09e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive model only credit hours comparison\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "tmp = df[['sem_load_credit_hours', 'sem_load_predicted', 'student_dropped_program']].dropna().copy()\n",
    "Xtrain = tmp[['sem_load_credit_hours']]\n",
    "ytrain = tmp[['student_dropped_program']]\n",
    "    \n",
    "# building the model and fitting the data\n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit()\n",
    "\n",
    "# ROC bootstrap\n",
    "n = 1000\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    \n",
    "    inds = np.random.randint(0, len(Xtrain), size=len(Xtrain))\n",
    "    xt = Xtrain.iloc[inds]\n",
    "    yt = ytrain.iloc[inds]\n",
    "\n",
    "    res.append(roc_auc_score(yt, log_reg.predict(xt)))\n",
    "\n",
    "print(f'M = {np.mean(res)} , 95% CI = [{np.quantile(res, 0.025)} , {np.quantile(res, 0.975)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Space Dropout\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "tmp = df[['sem_load_credit_hours', 'sem_load_predicted', 'student_dropped_program']].dropna().copy()\n",
    "Xtrain = tmp[['sem_load_credit_hours', 'sem_load_predicted']]\n",
    "ytrain = tmp[['student_dropped_program']]\n",
    "print(tmp.shape)\n",
    "    \n",
    "# building the model and fitting the data\n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit()\n",
    "\n",
    "print(log_reg.summary())\n",
    "\n",
    "y = np.array(Xtrain['sem_load_credit_hours'])\n",
    "x = np.array(Xtrain['sem_load_predicted'])\n",
    "z = np.array(ytrain['student_dropped_program'])\n",
    "\n",
    "x_pred = np.linspace(0, 35, 100)      # range of porosity values\n",
    "y_pred = np.linspace(0, 35, 100)   # range of VR values\n",
    "xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "model_viz = np.array([yy_pred.flatten(), xx_pred.flatten()]).T\n",
    "predicted = log_reg.predict(model_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 14))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "fig.tight_layout(pad=2)\n",
    "\n",
    "ax.plot(y, x, z, color='k', zorder=15, linestyle='none', marker='o', alpha=0.04)\n",
    "ax.scatter(yy_pred.flatten(), xx_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n",
    "ax.set_xlabel('Credit Hour Semester Load', fontsize=24)\n",
    "ax.set_ylabel('Predicted Semester Load', fontsize=24)\n",
    "ax.set_zlabel('P(Stop-Out)', fontsize=24)\n",
    "ax.locator_params(nbins=4, axis='x')\n",
    "ax.locator_params(nbins=5, axis='x')\n",
    "\n",
    "ax.set_xticks([0, 10, 20, 30, 40])\n",
    "ax.set_yticks([0, 10, 20, 30, 40])\n",
    "ax.set_zticks([0, .5, 1])\n",
    "\n",
    "ax.set_xticklabels([0, 10, 20, 30, 40], fontsize=24)\n",
    "ax.set_yticklabels([0, 10, 20, 30, 40], fontsize=24)\n",
    "ax.set_zticklabels([0, .5, 1], fontsize=24)\n",
    "\n",
    "ax.xaxis.labelpad=15\n",
    "ax.yaxis.labelpad=15 \n",
    "ax.zaxis.labelpad=7.5\n",
    "\n",
    "plt.savefig(\"../plots/dropout-model-space.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a096fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Space On-Time Graduation\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "tmp = df[['sem_load_credit_hours', 'sem_load_predicted', 'graduated_on_time']].dropna().copy()\n",
    "tmp['graduated_on_time'] = tmp['graduated_on_time'].map(lambda x: 0 if x == True else 1)\n",
    "Xtrain = tmp[['sem_load_credit_hours', 'sem_load_predicted']]\n",
    "ytrain = tmp[['graduated_on_time']]\n",
    "print(tmp.shape)\n",
    "\n",
    "# building the model and fitting the data\n",
    "log_reg = smf.logit(formula='graduated_on_time ~ sem_load_predicted + sem_load_credit_hours + sem_load_predicted:sem_load_credit_hours', data=tmp).fit()\n",
    "\n",
    "print(log_reg.summary())\n",
    "\n",
    "y = np.array(Xtrain['sem_load_credit_hours'])\n",
    "x = np.array(Xtrain['sem_load_predicted'])\n",
    "z = np.array(ytrain['graduated_on_time'])\n",
    "\n",
    "x_pred = np.linspace(0, 35, 100)      # range of porosity values\n",
    "y_pred = np.linspace(0, 35, 100)   # range of VR values\n",
    "\n",
    "xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "\n",
    "predicted = log_reg.predict(pd.DataFrame({'sem_load_credit_hours': yy_pred.flatten(), 'sem_load_predicted': xx_pred.flatten()}))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot(y, x, z, color='k', zorder=15, linestyle='none', marker='o', alpha=0.01)\n",
    "ax.scatter(yy_pred.flatten(), xx_pred.flatten(), predicted, facecolor=(0,0,0,0), s=20, edgecolor='#70b3f0')\n",
    "ax.set_xlabel('Credit Hour Semester Load', fontsize=12)\n",
    "ax.set_ylabel('Predicted Semester Load', fontsize=12)\n",
    "ax.set_zlabel('Delayed Graduation', fontsize=12)\n",
    "ax.locator_params(nbins=4, axis='x')\n",
    "ax.locator_params(nbins=5, axis='x')\n",
    "fig.tight_layout()\n",
    "\n",
    "ax.set_xticks([0, 10, 20, 30, 40])\n",
    "ax.set_yticks([0, 10, 20, 30, 40])\n",
    "ax.set_zticks([0, .5, 1])\n",
    "\n",
    "ax.set_xticklabels([0, 10, 20, 30, 40], fontsize=14)\n",
    "ax.set_yticklabels([0, 10, 20, 30, 40], fontsize=14)\n",
    "ax.set_zticklabels([0, .5, 1], fontsize=14)\n",
    "\n",
    "plt.savefig(\"../plots/on-time-graduation-model-space.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf87e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ROC bootstrap\n",
    "n = 1000\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    \n",
    "    inds = np.random.randint(0, len(Xtrain), size=len(Xtrain))\n",
    "    xt = Xtrain.iloc[inds]\n",
    "    yt = ytrain.iloc[inds]\n",
    "\n",
    "    res.append(roc_auc_score(yt, log_reg.predict(xt)))\n",
    "\n",
    "print(f'M = {np.mean(res)} , 95% CI = [{np.quantile(res, 0.025)} , {np.quantile(res, 0.975)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51925742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive model only credit hours comparison\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "tmp = df[['sem_load_credit_hours', 'sem_load_predicted', 'graduated_on_time']].dropna().copy()\n",
    "tmp['graduated_on_time'] = tmp['graduated_on_time'].map(lambda x: 0 if x == True else 1)\n",
    "Xtrain = tmp[['sem_load_credit_hours', 'sem_load_predicted']]\n",
    "ytrain = tmp[['graduated_on_time']]\n",
    "\n",
    "# building the model and fitting the data\n",
    "log_reg = smf.logit(formula='graduated_on_time ~ sem_load_credit_hours', data=tmp).fit()\n",
    "\n",
    "    \n",
    "# building the model and fitting the data\n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit()\n",
    "\n",
    "# ROC bootstrap\n",
    "n = 1000\n",
    "res = []\n",
    "for _ in tqdm(range(n)):\n",
    "    \n",
    "    inds = np.random.randint(0, len(Xtrain), size=len(Xtrain))\n",
    "    xt = Xtrain.iloc[inds]\n",
    "    yt = ytrain.iloc[inds]\n",
    "\n",
    "    res.append(roc_auc_score(yt, log_reg.predict(xt)))\n",
    "\n",
    "print(f'M = {np.mean(res)} , 95% CI = [{np.quantile(res, 0.025)} , {np.quantile(res, 0.975)}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
