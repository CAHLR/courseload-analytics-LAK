{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use one thread\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1\n",
    "\n",
    "# Do not use GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8acaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import inspect\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "import textwrap\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import pearsonr, mode\n",
    "from sklearn.base import clone\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, f1_score, accuracy_score, mean_absolute_error, log_loss\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, KFold\n",
    "from sklearn.svm import SVR\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_INDIV_SURVEY_VARS = True\n",
    "USE_IMPORTANCE_ITEMS = False\n",
    "\n",
    "df = pd.read_csv('./research-data/processed/lak22-courseload-final-studydata.csv')\n",
    "\n",
    "ADDITIONAL_INDIV_VARS = [\n",
    "    'course_name_number', 'is_stem_course', 'is_stem_student', 'course_student_stem_match',\n",
    "     'n_satisfied_prereqs_2021_Spring', 'n_satisfied_prereqs_all_past_semesters',\n",
    "    'percent_satisfied_prereqs_2021_Spring', 'percent_satisfied_prereqs_all_past_semesters',\n",
    "    'is_non_letter_grade_course', 'student_gpa', 'student_gpa_major', \n",
    "    'tl_importance', 'me_importance', 'ps_importance', 'combined_importance', \n",
    "    'tl_manage', 'me_manage', 'ps_manage', 'cl_combined_manage'\n",
    "]\n",
    "if not USE_IMPORTANCE_ITEMS:\n",
    "    for var in ['tl_importance', 'me_importance', 'ps_importance', 'combined_importance']:\n",
    "        del df[var]\n",
    "\n",
    "if not USE_INDIV_SURVEY_VARS:\n",
    "    for var in ADDITIONAL_INDIV_VARS:\n",
    "        del df[var]\n",
    "\n",
    "# Remove string section information\n",
    "for col in ['section_num','secondary_section_number','all_section_numbers']:\n",
    "    if col in df.columns:\n",
    "        del df[col]\n",
    "        \n",
    "# Remove Labels that are not needed\n",
    "for col in ['tl2', 'tl_sensitivity', 'me_sensitivity', 'ps_sensitivity', 'cl_sensitivity',\n",
    "            'tl1_smoothed_lmm', 'me_smoothed_lmm', 'ps_smoothed_lmm', 'cl_smoothed_lmm', \n",
    "            'tl1_smoothed_student_average', 'me_smoothed_student_average', 'ps_smoothed_student_average',\n",
    "            'cl_smoothed_student_average']:\n",
    "    if col in df.columns:\n",
    "        del df[col]\n",
    "\n",
    "# Drop string columns and get dummies for string var\n",
    "df = df.set_index('course_name_number')\n",
    "df = pd.get_dummies(df, columns=['class_type']) # upper, lower division, grad\n",
    "\n",
    "# Train (CV) and holdout\n",
    "train, test = train_test_split(df, test_size=0.15, random_state=12345, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e65ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./workload-ml/models/model-results-25-control variables.p', 'rb') as f:\n",
    "    MODELS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSEN_MODELS = {\n",
    "    'tl1': 'linreg',\n",
    "    'me': 'xgb',\n",
    "    'ps': 'xgb',\n",
    "    'cl_combined': 'ensemble'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extrapolations(f = '../research-data/processed/course-features-2021 Spring.csv'):\n",
    "    \n",
    "    # Read file\n",
    "    X_all = pd.read_csv(f)\n",
    "    \n",
    "    # Keep secondary section numbers based on which the prediction was made\n",
    "    secondary_sections = list(X_all['secondary_section_number'].values)\n",
    "\n",
    "    # Input transformation for models\n",
    "    X_all = X_all.set_index('course_name_number')\n",
    "    X_all = pd.get_dummies(X_all, columns=['class_type'])\n",
    "    X_all.drop(columns=list(set(X_all.columns) - set(train.columns)), inplace=True)\n",
    "\n",
    "    # Rename for model input\n",
    "    X_all['n_satisfied_prereqs_2021_Spring'] = X_all['n_satisfied_prereqs_current_semester']\n",
    "    X_all['percent_satisfied_prereqs_2021_Spring'] = X_all['percent_satisfied_prereqs_current_semester']\n",
    "\n",
    "    \n",
    "    # Initalize labels\n",
    "    LABELS = ['tl1', 'me', 'ps', 'cl_combined']\n",
    "\n",
    "    for l in LABELS:\n",
    "        X_all[l] = 1\n",
    "    \n",
    "    # Run\n",
    "    ignore_warnings=True\n",
    "    if ignore_warnings:\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    extrapolations = dict()\n",
    "    for l in LABELS: extrapolations[l] = dict()    \n",
    "\n",
    "    for target in LABELS:\n",
    "        for model in ['random', 'linreg', 'rf', 'xgb', 'enet', 'svm', 'nn']:\n",
    "            extrapolations[target][model] = apply_model(MODELS, train.copy(), X_all.copy(), \n",
    "                                                        target=target, model_ref=model,\n",
    "                                                        imputing_strategy='control variables')\n",
    "    # Add ensemble\n",
    "    for target in LABELS:\n",
    "        temp = []\n",
    "        for model in ['linreg', 'rf', 'xgb', 'enet', 'svm', 'nn']:\n",
    "            temp.append(extrapolations[target][model][0])\n",
    "        extrapolations[target]['ensemble'] = (list(map(np.mean, zip(*temp))), extrapolations[target]['linreg'][1])\n",
    "        \n",
    "    for label in CHOOSEN_MODELS.keys():\n",
    "        X_all[label] = extrapolations[label][CHOOSEN_MODELS[label]][0]\n",
    "    \n",
    "    # Export predictions\n",
    "    ref = f.split('-')[-1].split('.')[0]\n",
    "    outf = f'../research-data/processed/predicted-course-loads-{ref}.csv'\n",
    "    outdf = X_all[LABELS]\n",
    "    outdf['secondary_sections'] = secondary_sections\n",
    "    outdf.to_csv(outf, index=True)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = [\n",
    "    '../research-data/processed/course-features-2017 Spring.csv',\n",
    "    '../research-data/processed/course-features-2017 Fall.csv',\n",
    "    '../research-data/processed/course-features-2018 Spring.csv',\n",
    "    '../research-data/processed/course-features-2018 Fall.csv',\n",
    "    '../research-data/processed/course-features-2019 Spring.csv',\n",
    "    '../research-data/processed/course-features-2019 Fall.csv',\n",
    "    '../research-data/processed/course-features-2020 Spring.csv',\n",
    "    '../research-data/processed/course-features-2020 Fall.csv',\n",
    "    '../research-data/processed/course-features-2021 Spring.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(fs):\n",
    "    get_extrapolations(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
